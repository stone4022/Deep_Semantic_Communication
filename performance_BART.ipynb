{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/BART2FC/checkpoint_20.pth\n",
      "model load!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:39<00:00,  4.70it/s]\n",
      "c:\\Users\\stone4022\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\stone4022\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\stone4022\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s> madam president for ethical reasons the group of the european radical alliance is opposed to any form of patenting of human beings or any of their biomolecular elements.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>mr president i would like to know if there is anything you can do to find out why air france has cancelled its regular and special flights to strasbourg.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>the irish inherited disorders organization has complained that it was misled and misinformed and its position misrepresented. it does not support the patenting of human gene sequences.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>this parliament cannot ignore these crimes and we should condemn these attacks. i beg you mr president to convey this condemnation to the spanish authorities and the victims.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>the conciliation failed for the following reasons. firstly parliament did not want to create a precedent. it has never accepted a type b committee in conciliation.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>we oppose the decision to take economic and monetary union into the third stage as well as finland s presence in the process for both political and economic reasons.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>economic and monetary union will lead to a federalized europe. this we oppose we think that the union should have developed into an alliance of independent states.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>madam president for all these reasons on behalf of the group of the party of european socialists i recommend that we vote for this text without amendment.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>that is why i have voted in favour of the decision on the eleven countries to be included in the third stage of emu as from january.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Transitmitted:  the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Real: <s>despite considerable efforts it was impossible to bridge the gap between the two institutions in particular with regard to the type of committee to be chosen for the act.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "[0.00446184]\n",
      "[1.08423093e-309]\n",
      "[1.08423093e-309]\n",
      "[1.08423093e-309]\n"
     ]
    }
   ],
   "source": [
    "# !usr/bin/env python\n",
    "# -*- coding:utf-8 _*-\n",
    "\"\"\"\n",
    "@Author: Huiqiang Xie\n",
    "@File: performance.py\n",
    "@Time: 2021/4/1 11:48\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from dataset_BART import EurDataset, collate_data\n",
    "from models.BART2FC import DeepSC_BART2FC\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import BleuScore, SNR_to_noise, test_bart2fc\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-dir', default='./data/BART/train_data.pkl', type=str)\n",
    "parser.add_argument('--checkpoint-path', default='./checkpoints/BART2FC/', type=str)\n",
    "parser.add_argument('--channel', default='TEST', type=str)\n",
    "parser.add_argument('--MAX-LENGTH', default=70, type=int)\n",
    "parser.add_argument('--batch-size', default=64, type=int)\n",
    "parser.add_argument('--Test-epochs', default=1, type=int)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "\n",
    "def performance(args, SNR, net, pad_idx, start_idx, end_idx):\n",
    "#    similarity = Similarity(args.bert_config_path, args.bert_checkpoint_path, args.bert_dict_path)\n",
    "    bleu_score_1gram = BleuScore(1, 0, 0, 0)\n",
    "    bleu_score_2gram = BleuScore(0, 1, 0, 0)\n",
    "    bleu_score_3gram = BleuScore(0, 0, 1, 0)\n",
    "    bleu_score_4gram = BleuScore(0, 0, 0, 1)\n",
    "\n",
    "    test_eur = EurDataset('test')\n",
    "    test_iterator = DataLoader(test_eur, batch_size=args.batch_size, num_workers=0,\n",
    "                               pin_memory=True, collate_fn=collate_data)\n",
    "    \n",
    "    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "    score1 = []\n",
    "    score2 = []\n",
    "    score3 = []\n",
    "    score4 = []\n",
    "    sim_score_1 = []\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for epoch in range(args.Test_epochs):\n",
    "            Tx_word = []\n",
    "            Rx_word = []\n",
    "\n",
    "            for snr in SNR:\n",
    "                word = []\n",
    "                target_word = []\n",
    "                noise_std = SNR_to_noise(snr)\n",
    "\n",
    "                for sents in tqdm(test_iterator):\n",
    "                    sents = sents.to(device)\n",
    "                    # src = batch.src.transpose(0, 1)[:1]\n",
    "                    target = sents\n",
    "\n",
    "                    out = test_bart2fc(net, sents, noise_std, args.MAX_LENGTH, pad_idx,\n",
    "                                        start_idx, args.channel)\n",
    "\n",
    "                    sentences = out.cpu().numpy().tolist()\n",
    "                    for i in range(len(sentences)):\n",
    "                        result_string = tokenizer.decode(sentences[i])\n",
    "                        word = word + [result_string]\n",
    "\n",
    "                    target_sent = target.cpu().numpy().tolist()\n",
    "                    for i in range(len(target_sent)):\n",
    "                        result_string = tokenizer.decode(target_sent[i])\n",
    "                        target_word = target_word + [result_string]\n",
    "                    \n",
    "                Tx_word.append(word)\n",
    "                Rx_word.append(target_word)\n",
    "\n",
    "                for i in range(10):\n",
    "                    print('Transitmitted:', word[i])\n",
    "                    print('Real:', target_word[i])\n",
    "\n",
    "\n",
    "            bleu_score_1 = []\n",
    "            bleu_score_2 = []\n",
    "            bleu_score_3 = []\n",
    "            bleu_score_4 = []\n",
    "            sim_score = []\n",
    "\n",
    "            for sent1, sent2 in zip(Tx_word, Rx_word):\n",
    "                # 1-gram\n",
    "                bleu_score_1.append(bleu_score_1gram.compute_blue_score(sent1, sent2))\n",
    "                bleu_score_2.append(bleu_score_2gram.compute_blue_score(sent1, sent2))\n",
    "                bleu_score_3.append(bleu_score_3gram.compute_blue_score(sent1, sent2))\n",
    "                bleu_score_4.append(bleu_score_4gram.compute_blue_score(sent1, sent2))  # 7*num_sent\n",
    "                #sim_score.append(similarity.compute_similarity(sent1, sent2))  # 7*num_sent\n",
    "\n",
    "            bleu_score_1 = np.array(bleu_score_1)\n",
    "            bleu_score_1 = np.mean(bleu_score_1, axis=1)\n",
    "            score1.append(bleu_score_1)\n",
    "\n",
    "            bleu_score_2 = np.array(bleu_score_2)\n",
    "            bleu_score_2 = np.mean(bleu_score_2, axis=1)\n",
    "            score2.append(bleu_score_2)\n",
    "\n",
    "            bleu_score_3 = np.array(bleu_score_3)\n",
    "            bleu_score_3 = np.mean(bleu_score_3, axis=1)\n",
    "            score3.append(bleu_score_3)\n",
    "\n",
    "            bleu_score_4 = np.array(bleu_score_4)\n",
    "            bleu_score_4 = np.mean(bleu_score_4, axis=1)\n",
    "            score4.append(bleu_score_4)\n",
    "\n",
    "            #sim_score = np.array(sim_score)\n",
    "            #sim_score = np.mean(sim_score, axis=1)\n",
    "            #sim_score_1.append(sim_score)\n",
    "\n",
    "    bleu1gram = np.mean(np.array(score1), axis=0)\n",
    "    bleu2gram = np.mean(np.array(score2), axis=0)\n",
    "    bleu3gram = np.mean(np.array(score3), axis=0)\n",
    "    bleu4gram = np.mean(np.array(score4), axis=0)\n",
    "    #sim_score_1 = np.mean(np.array(sim_score), axis=0)\n",
    "\n",
    "    return bleu1gram, bleu2gram, bleu3gram, bleu4gram#, sim_score_1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parser.parse_args(args=[])\n",
    "    SNR = [0]\n",
    "    # SNR = [0, 3, 6, 9, 12, 15, 18]\n",
    "\n",
    "    start_idx = 0\n",
    "    pad_idx = 1\n",
    "    end_idx = 2\n",
    "\n",
    "    vocab_size = 50265\n",
    "    deepsc_bart2fc = DeepSC_BART2FC(vocab_size).to(device)\n",
    "\n",
    "    model_paths = []\n",
    "    for fn in os.listdir(args.checkpoint_path):\n",
    "        if not fn.endswith('.pth'): continue\n",
    "        idx = int(os.path.splitext(fn)[0].split('_')[-1])  # read the idx of image\n",
    "        model_paths.append((os.path.join(args.checkpoint_path, fn), idx))\n",
    "\n",
    "    model_paths.sort(key=lambda x: x[1])  # sort the image by the idx\n",
    "\n",
    "    model_path, _ = model_paths[-1]\n",
    "    print(model_path)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    deepsc_bart2fc.load_state_dict(checkpoint, strict=False)\n",
    "    print('model load!')\n",
    "\n",
    "    bleu_score1, bleu_score2, bleu_score3, bleu_score4 = performance(args, SNR, deepsc_bart2fc, pad_idx, start_idx, end_idx)\n",
    "    print(bleu_score1)\n",
    "    print(bleu_score2)\n",
    "    print(bleu_score3)\n",
    "    print(bleu_score4)\n",
    "\n",
    "    # similarity.compute_similarity(sent1, real)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73b135a1731027353d9e430fe90991fe4e44373132c253072ee09562ace0382d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
